{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Exploratory Data Analysis (EDA)\n",
    "\n",
    "**Objective:** To understand the fundamental characteristics of our selected assets: Tesla (TSLA), S&P 500 ETF (SPY), and Vanguard Total Bond Market ETF (BND). This phase involves fetching, cleaning, and visualizing the data to uncover trends, volatility patterns, and statistical properties that will inform our modeling strategy.\n",
    "\n",
    "**Stakeholder Insight:** This initial analysis is crucial for risk assessment. It helps us visually confirm the roles these assets are expected to play in a portfolio: TSLA for high-growth, SPY for market diversification, and BND for stability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Setup\n",
    "\n",
    "Import necessary libraries and configure the environment. We will use functions from our `src` package to ensure consistency with the production pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mseaborn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msns\u001b[39;00m\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import os\n",
    "import seaborn as sns\n",
    "import logging\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "# Ensure the 'src' directory is in the Python path to allow for modular imports\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from data_ingestion import get_data, check_stationarity, perform_eda_and_risk_analysis\n",
    "from config import TICKERS, REPORTS_DIR\n",
    "\n",
    "# Configure plots for better visualization and consistency\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 7)\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2. Data Ingestion and Preparation\n",
    "Here, we fetch the historical data for the defined tickers and save the processed DataFrame for use in subsequent analysis steps. This ensures data consistency across all notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch live or synthetic data for the required assets from the data ingestion module\n",
    "all_data = get_data(TICKERS)\n",
    "\n",
    "# Create the processed data directory if it doesn't exist\n",
    "os.makedirs('../data/processed', exist_ok=True)\n",
    "# Save the cleaned and prepared DataFrame to a CSV file\n",
    "all_data.to_csv('../data/processed/all_data.csv')\n",
    "\n",
    "print(\"Data successfully ingested and saved to ../data/processed/all_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Volatility Analysis: Daily Returns\n",
    "This section focuses on analyzing the volatility of each asset. We visualize the distribution of daily returns and track how volatility changes over time using a rolling standard deviation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the reports directory to save analysis artifacts\n",
    "os.makedirs(REPORTS_DIR, exist_ok=True)\n",
    "\n",
    "for asset in all_data.columns:\n",
    "    print(f\"\\n--- Volatility Analysis for {asset} ---\")\n",
    "    \n",
    "    # Calculate daily returns\n",
    "    daily_returns = all_data[asset].pct_change().dropna()\n",
    "    \n",
    "    # Visualize daily returns distribution to check for normality and fat tails\n",
    "    plt.figure()\n",
    "    daily_returns.hist(bins=50)\n",
    "    plt.title(f'Daily Returns Distribution for {asset}')\n",
    "    plt.xlabel('Daily Return')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.savefig(f'{REPORTS_DIR}/{asset}_daily_returns.png')\n",
    "    plt.show()\n",
    "    \n",
    "    # Visualize rolling volatility to observe how risk changes over time\n",
    "    rolling_std = daily_returns.rolling(window=20).std()\n",
    "    plt.figure()\n",
    "    rolling_std.plot()\n",
    "    plt.title(f'20-Day Rolling Volatility for {asset}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Volatility')\n",
    "    plt.savefig(f'{REPORTS_DIR}/{asset}_rolling_volatility.png')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stakeholder Insight\n",
    "\n",
    "The plot clearly shows:\n",
    "*   **TSLA:** Extreme volatility and exponential growth, confirming its status as a high-risk, high-reward asset.\n",
    "*   **SPY:** Steady, consistent growth that mirrors the overall US market.\n",
    "*   **BND:** Relative price stability, making it an effective hedge against equity market volatility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Data Stationarity Test\n",
    "Stationarity is a critical assumption for many time series models like ARIMA. Here, we perform the Augmented Dickey-Fuller (ADF) test for each asset to check if its time series is stationary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for asset in all_data.columns:\n",
    "    print(f\"\\n--- Stationarity Test for {asset} ---\")\n",
    "    # Check for stationarity, a critical assumption for many time series models\n",
    "    check_stationarity(all_data, asset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Conclusion and Next Steps\n",
    "This section summarizes the key findings from the EDA and outlines the next steps in the pipeline, which involves using this prepared data for forecasting and portfolio optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n--- EDA and Data Ingestion Complete ---\")\n",
    "print(\"Key findings:\")\n",
    "print(\"- The data has been successfully fetched, cleaned, and stored.\")\n",
    "print(\"- Daily returns and rolling volatility have been visualized to understand risk dynamics.\")\n",
    "print(\"- Stationarity tests have been performed for each asset, providing insights for time series modeling.\")\n",
    "print(\"All visualizations and reports have been saved to the 'reports' directory.\")\n",
    "print(\"\\nNext Steps: The prepared data is ready to be used for the Time Series Forecasting stage, where we will build predictive models.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
