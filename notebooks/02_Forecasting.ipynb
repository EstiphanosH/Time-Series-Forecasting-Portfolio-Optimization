{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Time Series Forecasting\n",
    "\n",
    "**Objective:** To build and evaluate a predictive model to forecast the future price of our high-growth asset, TSLA. A reliable forecast is the cornerstone of our data-driven portfolio strategy.\n",
    "\n",
    "**Stakeholder Insight:** By forecasting TSLA's expected return, we move beyond relying solely on historical averages. This allows us to incorporate a forward-looking view into our optimization, potentially capturing market dynamics more effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Setup\n",
    "\n",
    "Load the processed data from the previous step and import modeling libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add src directory to path for modular imports\n",
    "sys.path.append(os.path.abspath(os.path.join('..', 'src')))\n",
    "\n",
    "from data_ingestion import split_data\n",
    "from modeling import train_and_log_arima_model, get_forecast\n",
    "from evaluation import evaluate_model\n",
    "from config import FORECAST_ASSET, TRAIN_TEST_SPLIT_DATE\n",
    "\n",
    "# Configure plots for better visualization\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (15, 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2. Load and Prepare Data\n",
    "\n",
    "We load the cleaned data and split it into training and testing sets. The test set is reserved to provide an unbiased evaluation of our model's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-processed data from the previous step\n",
    "data = pd.read_csv('../data/processed/all_data.csv', index_col='Date', parse_dates=True)\n",
    "asset_data = data[FORECAST_ASSET]\n",
    "\n",
    "# CRITICAL FIX: The `split_data` function requires a split date from the config file.\n",
    "# Splitting data into a training set for model fitting and a test set for validation.\n",
    "train_data, test_data = split_data(asset_data, TRAIN_TEST_SPLIT_DATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3. ARIMA Model Training\n",
    "\n",
    "We use an **AutoRegressive Integrated Moving Average (ARIMA)** model. The `train_and_log_arima_model` function automatically searches for the optimal model parameters (p, d, q) and logs the results to MLflow for versioning and comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL FIX: Using the correct `train_and_log_arima_model` function from the updated pipeline.\n",
    "# This function now takes both training and testing data for a comprehensive evaluation.\n",
    "model = train_and_log_arima_model(train_data, test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4. Model Evaluation\n",
    "\n",
    "We now evaluate our trained model on the unseen test data to see how well it performs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model's performance on the test set using standard metrics.\n",
    "evaluation_metrics = evaluate_model(model, test_data)\n",
    "print(\"Evaluation Metrics:\")\n",
    "print(evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stakeholder Insight\n",
    "\n",
    "The evaluation metrics (MAE, RMSE) give us a quantitative measure of the model's average prediction error in dollar terms. While no model is perfect, these low error values suggest our model is closely tracking the actual price, providing a solid foundation for our forecast."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5. Generate and Visualize Forecast\n",
    "\n",
    "With the model validated, we retrain it on the entire dataset and use it to forecast future prices. Visualizing the forecast with confidence intervals is key to understanding the uncertainty involved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the forecast for the specified period using the full dataset.\n",
    "annual_return, forecast, conf_int = get_forecast(model, asset_data)\n",
    "\n",
    "# Plot the forecast to visualize the future price trend and confidence intervals.\n",
    "plt.plot(asset_data['2023':], label='Historical Prices') # Plot recent history for context\n",
    "plt.plot(forecast, label='Forecast', color='red')\n",
    "plt.fill_between(forecast.index, conf_int.iloc[:, 0], conf_int.iloc[:, 1], color='pink', alpha=0.5, label='95% Confidence Interval')\n",
    "plt.title(f'{FORECAST_ASSET} Price Forecast for the Next Year')\n",
    "plt.ylabel('Price (USD)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stakeholder Recommendation\n",
    "\n",
    "The forecast indicates an expected **annual return for TSLA**. This is a key input for the next phase of portfolio optimization. **Crucially, observe the widening confidence interval (the pink shaded area).** This visually represents that prediction certainty decreases significantly over time. While the model provides a valuable directional trend, long-range point forecasts should be treated with caution. This insight reinforces the need for periodic re-evaluation and rebalancing of the portfolio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CRITICAL FIX: Move Python formatting from markdown to a code cell to ensure it renders correctly.\n",
    "print(f\"The model-forecasted annual return is: {annual_return * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6. Conclusion and Next Steps\n",
    "\n",
    "We have successfully trained, evaluated, and used a forecasting model. The output—the expected annual return for TSLA—will now be a key input for our portfolio optimization.\n",
    "\n",
    "**Action:** Save the trained model and the forecasted return for the next phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory for model artifacts\n",
    "os.makedirs('../reports/artifacts', exist_ok=True)\n",
    "\n",
    "# Save the model for use in the dashboard or other applications\n",
    "joblib.dump(model, '../reports/artifacts/arima_model.pkl')\n",
    "\n",
    "# Save the forecast return for use in portfolio optimization\n",
    "with open('../reports/artifacts/forecast_return.json', 'w') as f:\n",
    "    json.dump({'annual_return': annual_return}, f)\n",
    "\n",
    "print(\"Model and forecast return saved to reports/artifacts/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}